# ç« èŠ‚ç»“æ„è¯†åˆ«å®ç°æ–‡æ¡£

## æ¦‚è¿°

ç« èŠ‚ç»“æ„è¯†åˆ«æ˜¯æ–‡æœ¬å¤„ç†çš„ç¬¬äºŒä¸ªå…³é”®æ­¥éª¤ï¼Œç›®æ ‡æ˜¯ä»å°è¯´æ–‡æœ¬ä¸­è‡ªåŠ¨è¯†åˆ«å’Œæå–ç« èŠ‚ä¿¡æ¯ï¼Œå»ºç«‹å®Œæ•´çš„ç« èŠ‚ç»“æ„æ ‘ã€‚

## åŠŸèƒ½éœ€æ±‚

### æ ¸å¿ƒåŠŸèƒ½
1. **ç« èŠ‚è¾¹ç•Œè¯†åˆ«** - å‡†ç¡®å®šä½æ¯ä¸ªç« èŠ‚çš„å¼€å§‹å’Œç»“æŸä½ç½®
2. **ç« èŠ‚æ ‡é¢˜æå–** - æå–ç« èŠ‚çš„å®Œæ•´æ ‡é¢˜ä¿¡æ¯
3. **å±‚çº§ç»“æ„æ„å»º** - å¤„ç†å·ã€ç« ã€èŠ‚ç­‰å¤šçº§ç»“æ„
4. **å…ƒæ•°æ®æå–** - æå–ç« èŠ‚ç¼–å·ã€å­—æ•°ç»Ÿè®¡ç­‰ä¿¡æ¯

### æ‰©å±•åŠŸèƒ½
1. **å¼‚å¸¸å¤„ç†** - å¤„ç†æ ¼å¼ä¸è§„èŒƒçš„ç« èŠ‚æ ‡é¢˜
2. **çµæ´»é…ç½®** - æ”¯æŒä¸åŒå°è¯´çš„ç« èŠ‚æ ¼å¼
3. **éªŒè¯æœºåˆ¶** - ç¡®ä¿ç« èŠ‚åˆ’åˆ†çš„å®Œæ•´æ€§å’Œå‡†ç¡®æ€§

## æŠ€æœ¯å®ç°æ–¹æ¡ˆ

### 1. ç« èŠ‚æ ‡è¯†ç¬¦åˆ†æ

åŸºäºå¯¹ `ziyang.txt` çš„åˆ†æï¼Œå¸¸è§çš„ç« èŠ‚æ ‡è¯†ç¬¦åŒ…æ‹¬ï¼š

```python
CHAPTER_PATTERNS = [
    r'^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡\d]+å·\s+(.+)$',  # å·æ ‡é¢˜ï¼šç¬¬ä¸€å· é“äºº
    r'^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡\d]+ç« \s+(.+)$',  # ç« æ ‡é¢˜ï¼šç¬¬ä¸€ç«  æ–°å©šå¤§å–œ
    r'^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡\d]+èŠ‚\s+(.+)$',  # èŠ‚æ ‡é¢˜ï¼ˆå¦‚æœæœ‰ï¼‰
    r'^[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡\d]+ã€(.+)$',      # æ•°å­—åºå·æ ¼å¼
    r'^\d+\.?\s*(.+)$',                              # é˜¿æ‹‰ä¼¯æ•°å­—æ ¼å¼
]
```

### 2. æ ¸å¿ƒç®—æ³•å®ç°

#### ChapterParser ç±»è®¾è®¡

```python
class ChapterParser:
    def __init__(self, config=None):
        self.config = config or self._default_config()
        self.chapters = []
        self.volumes = []
    
    def parse_file(self, file_path):
        """è§£ææ•´ä¸ªæ–‡ä»¶çš„ç« èŠ‚ç»“æ„"""
        
    def _identify_chapter_lines(self, lines):
        """è¯†åˆ«ç« èŠ‚æ ‡é¢˜è¡Œ"""
        
    def _build_chapter_structure(self, chapter_lines):
        """æ„å»ºç« èŠ‚ç»“æ„æ ‘"""
        
    def _extract_content(self, lines, start, end):
        """æå–ç« èŠ‚å†…å®¹"""
        
    def _validate_structure(self):
        """éªŒè¯ç« èŠ‚ç»“æ„çš„å®Œæ•´æ€§"""
```

### 3. æ•°æ®ç»“æ„è®¾è®¡

#### ç« èŠ‚ä¿¡æ¯ç»“æ„

```python
@dataclass
class Chapter:
    volume_title: str          # æ‰€å±å·æ ‡é¢˜
    volume_number: int         # å·ç¼–å·
    chapter_title: str         # ç« èŠ‚æ ‡é¢˜
    chapter_number: int        # ç« èŠ‚ç¼–å·
    start_line: int           # å¼€å§‹è¡Œå·
    end_line: int             # ç»“æŸè¡Œå·
    content: str              # ç« èŠ‚å†…å®¹
    word_count: int           # å­—æ•°ç»Ÿè®¡
    metadata: dict            # é¢å¤–å…ƒæ•°æ®

@dataclass
class Volume:
    title: str                # å·æ ‡é¢˜
    number: int               # å·ç¼–å·
    chapters: List[Chapter]   # åŒ…å«çš„ç« èŠ‚åˆ—è¡¨
    start_line: int           # å¼€å§‹è¡Œå·
    end_line: int             # ç»“æŸè¡Œå·
```

## å…·ä½“å®ç°æ­¥éª¤

### æ­¥éª¤1ï¼šæ–‡æœ¬é¢„å¤„ç†

```python
def preprocess_text(self, file_path):
    """
    é¢„å¤„ç†æ–‡æœ¬ï¼Œä¸ºç« èŠ‚è¯†åˆ«åšå‡†å¤‡
    """
    with open(file_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    # æ¸…ç†ç©ºè¡Œå’Œç‰¹æ®Šå­—ç¬¦
    cleaned_lines = []
    for i, line in enumerate(lines):
        cleaned_line = line.strip()
        if cleaned_line:
            cleaned_lines.append((i+1, cleaned_line))  # ä¿å­˜åŸå§‹è¡Œå·
    
    return cleaned_lines
```

### æ­¥éª¤2ï¼šç« èŠ‚æ ‡è¯†ç¬¦åŒ¹é…

```python
def identify_chapter_lines(self, lines):
    """
    è¯†åˆ«æ‰€æœ‰å¯èƒ½çš„ç« èŠ‚æ ‡é¢˜è¡Œ
    """
    chapter_candidates = []
    
    for line_num, line_content in lines:
        for pattern in self.config['chapter_patterns']:
            match = re.match(pattern, line_content)
            if match:
                chapter_info = {
                    'line_number': line_num,
                    'raw_text': line_content,
                    'matched_pattern': pattern,
                    'extracted_title': match.group(1) if match.groups() else line_content,
                    'type': self._determine_chapter_type(pattern)
                }
                chapter_candidates.append(chapter_info)
                break
    
    return chapter_candidates
```

### æ­¥éª¤3ï¼šå±‚çº§ç»“æ„æ„å»º

```python
def build_hierarchy(self, chapter_candidates, all_lines):
    """
    æ„å»ºç« èŠ‚çš„å±‚çº§ç»“æ„
    """
    volumes = []
    current_volume = None
    chapters = []
    
    for i, candidate in enumerate(chapter_candidates):
        if candidate['type'] == 'volume':
            # å¤„ç†å·çº§åˆ«
            if current_volume:
                current_volume['chapters'] = chapters
                volumes.append(current_volume)
            
            current_volume = {
                'title': candidate['extracted_title'],
                'line_number': candidate['line_number'],
                'chapters': []
            }
            chapters = []
            
        elif candidate['type'] == 'chapter':
            # å¤„ç†ç« çº§åˆ«
            next_line = chapter_candidates[i+1]['line_number'] if i+1 < len(chapter_candidates) else len(all_lines)
            
            chapter = {
                'title': candidate['extracted_title'],
                'start_line': candidate['line_number'],
                'end_line': next_line - 1,
                'content': self._extract_content(all_lines, candidate['line_number'], next_line - 1)
            }
            chapters.append(chapter)
    
    # å¤„ç†æœ€åä¸€ä¸ªå·
    if current_volume:
        current_volume['chapters'] = chapters
        volumes.append(current_volume)
    
    return volumes
```

### æ­¥éª¤4ï¼šå†…å®¹æå–å’Œç»Ÿè®¡

```python
def extract_content(self, lines, start_line, end_line):
    """
    æå–æŒ‡å®šèŒƒå›´å†…çš„ç« èŠ‚å†…å®¹
    """
    content_lines = []
    word_count = 0
    
    for line_num, line_content in lines:
        if start_line < line_num <= end_line:
            content_lines.append(line_content)
            word_count += len(line_content.replace(' ', ''))
    
    return {
        'content': '\n'.join(content_lines),
        'word_count': word_count,
        'line_count': len(content_lines)
    }
```

## é…ç½®æ–‡ä»¶è®¾è®¡

### chapter_config.json

```json
{
    "patterns": {
        "volume": [
            "^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡\\d]+å·\\s+(.+)$"
        ],
        "chapter": [
            "^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡\\d]+ç« \\s+(.+)$"
        ],
        "section": [
            "^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡\\d]+èŠ‚\\s+(.+)$"
        ]
    },
    "numbering": {
        "chinese_numerals": true,
        "arabic_numerals": true,
        "mixed_format": true
    },
    "validation": {
        "min_chapter_length": 100,
        "max_chapter_length": 50000,
        "require_continuous_numbering": false
    }
}
```

## è¾“å‡ºæ ¼å¼è®¾è®¡

### JSON è¾“å‡ºæ ¼å¼

```json
{
    "metadata": {
        "source_file": "data/ziyang.txt",
        "total_volumes": 1,
        "total_chapters": 156,
        "total_words": 2010091,
        "processed_time": "2024-07-02T17:30:00Z"
    },
    "structure": [
        {
            "volume": {
                "title": "é“äºº",
                "number": 1,
                "start_line": 8,
                "chapters": [
                    {
                        "title": "æ–°å©šå¤§å–œ",
                        "number": 1,
                        "start_line": 11,
                        "end_line": 520,
                        "word_count": 3524,
                        "content_preview": "å…¬å…ƒ340å¹´å†¬ï¼Œé»„æ²³åŒ—å²¸ï¼Œè¥¿é˜³å¿ä¸œéƒŠ...",
                        "characters_mentioned": ["è«å‡¡", "è€å…ˆç”Ÿ"],
                        "dialogue_count": 15
                    }
                ]
            }
        }
    ]
}
```

## é”™è¯¯å¤„ç†å’Œè¾¹ç•Œæƒ…å†µ

### 1. æ ¼å¼å¼‚å¸¸å¤„ç†

```python
def handle_format_exceptions(self, line_content):
    """
    å¤„ç†æ ¼å¼ä¸è§„èŒƒçš„ç« èŠ‚æ ‡é¢˜
    """
    # å¤„ç†æ ‡é¢˜ä¸­åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„æƒ…å†µ
    cleaned_title = re.sub(r'[^\u4e00-\u9fff\w\s]', '', line_content)
    
    # å¤„ç†ç¼–å·ä¸è¿ç»­çš„æƒ…å†µ
    if self.config['validation']['require_continuous_numbering']:
        # å®ç°ç¼–å·è¿ç»­æ€§æ£€æŸ¥
        pass
    
    return cleaned_title
```

### 2. éªŒè¯æœºåˆ¶

```python
def validate_chapter_structure(self, chapters):
    """
    éªŒè¯ç« èŠ‚ç»“æ„çš„åˆç†æ€§
    """
    issues = []
    
    for i, chapter in enumerate(chapters):
        # æ£€æŸ¥ç« èŠ‚é•¿åº¦
        if chapter['word_count'] < self.config['validation']['min_chapter_length']:
            issues.append(f"ç« èŠ‚ {chapter['title']} å†…å®¹è¿‡çŸ­")
        
        # æ£€æŸ¥ç« èŠ‚è¾¹ç•Œ
        if i > 0 and chapter['start_line'] <= chapters[i-1]['end_line']:
            issues.append(f"ç« èŠ‚ {chapter['title']} è¾¹ç•Œé‡å ")
    
    return issues
```

## æ€§èƒ½ä¼˜åŒ–

### 1. å†…å­˜ä¼˜åŒ–
- åˆ†å—å¤„ç†å¤§æ–‡ä»¶
- å»¶è¿ŸåŠ è½½ç« èŠ‚å†…å®¹
- ä½¿ç”¨ç”Ÿæˆå™¨å‡å°‘å†…å­˜å ç”¨

### 2. å¤„ç†é€Ÿåº¦ä¼˜åŒ–
- ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
- ä½¿ç”¨å¤šè¿›ç¨‹å¤„ç†å¤§æ–‡ä»¶
- ç¼“å­˜ä¸­é—´ç»“æœ

## æµ‹è¯•ç”¨ä¾‹è®¾è®¡

### å•å…ƒæµ‹è¯•

```python
def test_chapter_recognition():
    test_cases = [
        ("ç¬¬ä¸€ç«  æ–°å©šå¤§å–œ", True, "æ–°å©šå¤§å–œ"),
        ("ç¬¬äºŒåä¸‰ç« ã€€å¤œè¢­", True, "å¤œè¢­"),
        ("æ™®é€šæ–‡æœ¬å†…å®¹", False, None),
        ("ç¬¬1ç«  ç°ä»£æ ¼å¼", True, "ç°ä»£æ ¼å¼")
    ]
    
    parser = ChapterParser()
    for text, should_match, expected_title in test_cases:
        result = parser.is_chapter_title(text)
        assert result == should_match
        if should_match:
            assert parser.extract_title(text) == expected_title
```


## å·²å®ç°åŠŸèƒ½ âœ…

### ç« èŠ‚ç»“æ„å¯è§†åŒ–å·¥å…·

**å®ç°æ–‡ä»¶ï¼š** `src/step02_chapter/chapter_visualizer.py`

**åŠŸèƒ½ç‰¹ç‚¹ï¼š**
- ğŸ“Š **å¤šç§æ ¼å¼**ï¼šæ”¯æŒæ–‡æœ¬ã€æ ‘çŠ¶ã€HTMLã€JSONå››ç§å¯è§†åŒ–æ ¼å¼
- ğŸ—ï¸ **å±‚çº§ç»“æ„**ï¼šè‡ªåŠ¨è¯†åˆ«å·å’Œç« èŠ‚çš„å±‚çº§å…³ç³»
- ğŸ“ˆ **ç»Ÿè®¡ä¿¡æ¯**ï¼šæ˜¾ç¤ºå­—æ•°ã€ç« èŠ‚æ•°ç­‰ç»Ÿè®¡æ•°æ®
- ğŸ¨ **HTMLå¯è§†åŒ–**ï¼šç”Ÿæˆç¾è§‚çš„ç½‘é¡µç‰ˆå¯è§†åŒ–ç•Œé¢

**ä½¿ç”¨ç¤ºä¾‹ï¼š**
```bash
# æ ‘çŠ¶ç»“æ„æ˜¾ç¤º
python src/step02_chapter/chapter_visualizer.py data/ziyang.txt -f tree

# ç”ŸæˆHTMLå¯è§†åŒ–æ–‡ä»¶
python src/step02_chapter/chapter_visualizer.py data/ziyang.txt -f html -o output/chapter_structure.html

# æ–‡æœ¬æ ¼å¼è¯¦ç»†æ˜¾ç¤º
python src/step02_chapter/chapter_visualizer.py data/ziyang.txt -f text

# JSONæ ¼å¼è¾“å‡º
python src/step02_chapter/chapter_visualizer.py data/ziyang.txt -f json -o output/chapter_structure.json
```

**è§£æç»“æœï¼š**
- è¯†åˆ«å‡º7å·ï¼Œ535ç« ï¼Œå…±1,894,212å­—
- è‡ªåŠ¨è§£æç« èŠ‚æ ‡é¢˜å’Œå­—æ•°ç»Ÿè®¡
- ç”Ÿæˆå®Œæ•´çš„ç« èŠ‚ç»“æ„æ ‘
- HTMLç‰ˆæœ¬åŒ…å«è¿›åº¦æ¡å’Œå­—æ•°å æ¯”å¯è§†åŒ–

### æ ¸å¿ƒç®—æ³•å®ç°

**ChapterStructureVisualizerç±»ï¼š**
- æ”¯æŒä¸­æ–‡æ•°å­—å’Œé˜¿æ‹‰ä¼¯æ•°å­—çš„ç« èŠ‚ç¼–å·è¯†åˆ«
- è‡ªåŠ¨æ„å»ºå·-ç« å±‚çº§ç»“æ„
- æä¾›å¤šç§è¾“å‡ºæ ¼å¼çš„å¯è§†åŒ–å±•ç¤º
- åŒ…å«å­—æ•°ç»Ÿè®¡å’Œç« èŠ‚å†…å®¹é¢„è§ˆåŠŸèƒ½

**æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼ï¼š**
```python
patterns = {
    'volume': [
        r'^ç¬¬([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡\d]+)å·\s+(.+)$',
        r'^ç¬¬(\d+)å·\s+(.+)$'
    ],
    'chapter': [
        r'^ç¬¬([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡\d]+)ç« \s+(.+)$', 
        r'^ç¬¬(\d+)ç« \s+(.+)$'
    ]
}
```

## åç»­æ‰©å±•

1. **æ™ºèƒ½å­¦ä¹ ** - åŸºäºå·²æ ‡æ³¨æ•°æ®è®­ç»ƒç« èŠ‚è¯†åˆ«æ¨¡å‹
2. **å¤šæ ¼å¼æ”¯æŒ** - æ”¯æŒæ›´å¤šå°è¯´æ ¼å¼å’Œç½‘ç«™æ ¼å¼
3. ~~**å¯è§†åŒ–å·¥å…·** - æä¾›ç« èŠ‚ç»“æ„çš„å¯è§†åŒ–å±•ç¤º~~ âœ… **å·²å®Œæˆ**
4. **æ‰¹é‡å¤„ç†** - æ”¯æŒæ‰¹é‡å¤„ç†å¤šä¸ªå°è¯´æ–‡ä»¶
5. **APIæ¥å£** - æä¾›REST APIä¾›å…¶ä»–åº”ç”¨è°ƒç”¨